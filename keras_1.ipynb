{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1、keras模块介绍"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "顾名思义，Optimizers包含了一些优化的方法，比如最基本的随机梯度下降SGD,另外还有Adagrad、Adadelta、RMSprop、Adam，一些新的方法以后也会被不断添加进来。\n",
    "\n",
    "keras.optimizers.SGD(lr=0.01, momentum=0.9, decay=0.9, nesterov=False)\n",
    "\n",
    "上面的代码是SGD的使用方法，lr表示学习速率,momentum表示动量项，decay是学习速率的衰减系数(每个epoch衰减一次),Nesterov的值是False或者True，表示使不使用Nesterov momentum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这是目标函数模块，keras提供了mean_squared_error，mean_absolute_error ，squared_hinge，hinge，binary_crossentropy，categorical_crossentropy这几种目标函数。\n",
    "\n",
    "这里binary_crossentropy 和 categorical_crossentropy也就是常说的logloss.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这是激活函数模块，keras提供了linear、sigmoid、hard_sigmoid、tanh、softplus、relu、softplus，另外softmax也放在Activations模块里(我觉得放在layers模块里更合理些）。此外，像LeakyReLU和PReLU这种比较新的激活函数，keras在keras.layers.advanced_activations模块里提供。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这是参数初始化模块，在添加layer的时候调用init进行初始化。keras提供了uniform、lecun_uniform、normal、orthogonal、zero、glorot_normal、he_normal这几种。 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "layers模块包含了core、convolutional、recurrent、advanced_activations、normalization、embeddings这几种layer。\n",
    "\n",
    "其中core里面包含了flatten(CNN的全连接层之前需要把二维特征图flatten成为一维的)、reshape（CNN输入时将一维的向量弄成二维的）、dense(就是隐藏层，dense是稠密的意思),还有其他的就不介绍了。convolutional层基本就是Theano的Convolution2D的封装。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这是预处理模块，包括序列数据的处理，文本数据的处理，图像数据的处理。重点看一下图像数据的处理，keras提供了ImageDataGenerator函数,实现data augmentation，数据集扩增，对图像做一些弹性变换，比如水平翻转，垂直翻转，旋转等。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这是最主要的模块，模型。上面定义了各种基本组件，model是将它们组合起来，下面通过一个实例来说明。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2、一个实例：用CNN分类Mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读取图片数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "keras要求输入的数据格式是numpy.array类型（numpy是一个python的数值计算的库），所以需要写一个脚本来读入mnist图像，保存为一个四维的data，还有一个一维的label，代码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#coding:utf-8\n",
    "\"\"\"\n",
    "Author:wepon\n",
    "Source:https://github.com/wepe\n",
    "file:data.py\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "#读取文件夹mnist下的42000张图片，图片为灰度图，所以为1通道，\n",
    "#如果是将彩色图作为输入,则将1替换为3，并且data[i,:,:,:] = arr改为data[i,:,:,:] = [arr[:,:,0],arr[:,:,1],arr[:,:,2]]\n",
    "def load_data():\n",
    "    data = np.empty((42000,1,28,28),dtype=\"float32\") #42000个一通道的数组，数组格式为28*28\n",
    "    label = np.empty((42000,),dtype=\"uint8\")\n",
    "\n",
    "    imgs = os.listdir(\"E:/machine_data/mnist\")   #os.listdir获取目录的内容\n",
    "    num = len(imgs)\n",
    "    for i in range(num):\n",
    "        img = Image.open(\"E:/machine_data/mnist/\"+imgs[i])\n",
    "        arr = np.asarray(img,dtype=\"float32\")  #将输入数据（列表的列表，元组的元组，元组的列表等）转换为矩阵形式\n",
    "        data[i,:,:,:] = arr\n",
    "        label[i] = int(imgs[i].split('.')[0])\n",
    "    return data,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.1.jpg', '0.10.jpg', '0.100.jpg', '0.1000.jpg', '0.1001.jpg', '0.1002.jpg', '0.1003.jpg', '0.1004.jpg', '0.1005.jpg']\n"
     ]
    }
   ],
   "source": [
    "imgs = os.listdir(\"E:/machine_data/mnist\")\n",
    "print (imgs[1:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42000\n"
     ]
    }
   ],
   "source": [
    "num = len(imgs)\n",
    "print (num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.   4.   6.   0.   0.   0.   0.   0.   1.   0.   0.   3.   0.   2.\n",
      "    0.   3.   0.   2.  11.   6.   0.   0.   3.   1.   0.   0.   0.   0.]]\n",
      "(28, 28)\n"
     ]
    }
   ],
   "source": [
    "img = Image.open(\"E:/machine_data/mnist/\"+imgs[1])\n",
    "arr = np.asarray(img,dtype=\"float32\")\n",
    "print (arr[0:1]) #28*28\n",
    "print (arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = np.empty((42000,1,28,28),dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data[1,:,:,:] = arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 1, 28, 28)\n",
      "[[  0.   4.   6.   0.   0.   0.   0.   0.   1.   0.   0.   3.   0.   2.\n",
      "    0.   3.   0.   2.  11.   6.   0.   0.   3.   1.   0.   0.   0.   0.]]\n"
     ]
    }
   ],
   "source": [
    "print (data.shape)\n",
    "print (data[1,0,:,:][0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2', '2063', 'jpg']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs[10000].split('.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 构建CNN，训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42000  samples\n",
      "[[ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda1\\lib\\site-packages\\ipykernel\\__main__.py:36: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(4, (5, 5), input_shape=(1, 28, 28..., padding=\"valid\")`\n",
      "D:\\anaconda1\\lib\\site-packages\\ipykernel\\__main__.py:42: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(8, (3, 3), padding=\"valid\")`\n",
      "D:\\anaconda1\\lib\\site-packages\\ipykernel\\__main__.py:49: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), padding=\"valid\")`\n",
      "D:\\anaconda1\\lib\\site-packages\\keras\\models.py:837: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n",
      "D:\\anaconda1\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2250: UserWarning: Expected no kwargs, you passed 1\n",
      "kwargs passed to function are ignored with Tensorflow backend\n",
      "  warnings.warn('\\n'.join(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 33600 samples, validate on 8400 samples\n",
      "Epoch 1/3\n",
      "33600/33600 [==============================] - 29s - loss: 0.1723 - acc: 0.9460 - val_loss: 8.5907 - val_acc: 0.0173\n",
      "Epoch 2/3\n",
      "33600/33600 [==============================] - 29s - loss: 0.0775 - acc: 0.9752 - val_loss: 9.5697 - val_acc: 0.0170\n",
      "Epoch 3/3\n",
      "33600/33600 [==============================] - 28s - loss: 0.0572 - acc: 0.9813 - val_loss: 10.4809 - val_acc: 0.0174\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x190fb4f6668>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#导入各种用到的模块组件\n",
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "#from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import SGD, Adadelta, Adagrad\n",
    "from keras.utils import np_utils, generic_utils\n",
    "from six.moves import range\n",
    "\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "\n",
    "#加载数据\n",
    "data, label = load_data()\n",
    "print(data.shape[0], ' samples')\n",
    "\n",
    "#label为0~9共10个类别，keras要求格式为binary class matrices,转化一下，直接调用keras提供的这个函数\n",
    "label = np_utils.to_categorical(label, 10)\n",
    "print (label[1:3])\n",
    "\n",
    "###############\n",
    "#开始建立CNN模型\n",
    "###############\n",
    "\n",
    "#生成一个model\n",
    "model = Sequential()\n",
    "\n",
    "#第一个卷积层，4个卷积核，每个卷积核大小5*5。1表示输入的图片的通道,灰度图为1通道。\n",
    "#border_mode可以是valid或者full，具体看这里说明：http://deeplearning.net/software/theano/library/tensor/nnet/conv.html#theano.tensor.nnet.conv.conv2d\n",
    "#激活函数用tanh\n",
    "#你还可以在model.add(Activation('tanh'))后加上dropout的技巧: model.add(Dropout(0.5))\n",
    "#input_shape=(3,224,224) is for \"theano\",   \"tensorflow\" should be input_shape=(224,224,3)\n",
    "model.add(Convolution2D(4,5,5,border_mode='valid', input_shape=(1,28,28))) \n",
    "model.add(Activation('tanh'))\n",
    "\n",
    "#第二个卷积层，8个卷积核，每个卷积核大小3*3。4表示输入的特征图个数，等于上一层的卷积核个数\n",
    "#激活函数用tanh\n",
    "#采用maxpooling，poolsize为(2,2)\n",
    "model.add(Convolution2D(8,3, 3, border_mode='valid'))\n",
    "model.add(Activation('tanh'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "#第三个卷积层，16个卷积核，每个卷积核大小3*3\n",
    "#激活函数用tanh\n",
    "#采用maxpooling，poolsize为(2,2)\n",
    "model.add(Convolution2D(16,3, 3, border_mode='valid')) \n",
    "model.add(Activation('tanh'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "#全连接层，先将前一层输出的二维特征图flatten为一维的。\n",
    "#Dense就是隐藏层。16就是上一层输出的特征图个数。4是根据每个卷积层计算出来的：(28-5+1)得到24,(24-3+1)/2得到11，(11-3+1)/2得到4\n",
    "#全连接有128个神经元节点,初始化方式为normal\n",
    "model.add(Flatten())\n",
    "model.add(Dense(16*4*4))\n",
    "model.add(Activation('tanh'))\n",
    "\n",
    "#Softmax分类，输出是10类别\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "#############\n",
    "#开始训练模型\n",
    "##############\n",
    "#使用SGD + momentum\n",
    "#model.compile里的参数loss就是损失函数(目标函数)\n",
    "sgd = SGD(lr=0.05, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd,class_mode=\"categorical\",metrics=['accuracy'])\n",
    "\n",
    "#调用fit方法，就是一个训练过程. 训练的epoch数设为10，batch_size为100．\n",
    "#数据经过随机打乱shuffle=True。verbose=1，训练过程中输出的信息，0、1、2三种方式都可以，无关紧要。show_accuracy=True，训练时每一个epoch都输出accuracy。\n",
    "#validation_split=0.2，将20%的数据作为验证集。\n",
    "model.fit(data, label, batch_size=100,nb_epoch=3,shuffle=True,verbose=1,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42000  samples\n",
      "[[ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda1\\lib\\site-packages\\ipykernel\\__main__.py:23: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(4, (5, 5), input_shape=(1, 28, 28..., padding=\"valid\")`\n",
      "D:\\anaconda1\\lib\\site-packages\\ipykernel\\__main__.py:27: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(8, (3, 3))`\n",
      "D:\\anaconda1\\lib\\site-packages\\keras\\models.py:837: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 33600 samples, validate on 8400 samples\n",
      "Epoch 1/3\n",
      "33600/33600 [==============================] - 15s - loss: 0.3226 - acc: 0.8961 - val_loss: 8.9395 - val_acc: 0.0169\n",
      "Epoch 2/3\n",
      "33600/33600 [==============================] - 14s - loss: 0.1764 - acc: 0.9440 - val_loss: 8.6072 - val_acc: 0.0165\n",
      "Epoch 3/3\n",
      "33600/33600 [==============================] - 14s - loss: 0.1511 - acc: 0.9517 - val_loss: 9.5022 - val_acc: 0.0160\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x190d09c2ba8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils, generic_utils\n",
    "\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "\n",
    "#加载数据\n",
    "data, label = load_data()\n",
    "print(data.shape[0], ' samples')\n",
    "\n",
    "#label为0~9共10个类别，keras要求格式为binary class matrices,转化一下，直接调用keras提供的这个函数\n",
    "label = np_utils.to_categorical(label, 10)\n",
    "print (label[1:3])\n",
    "X_train=data\n",
    "Y_train=label\n",
    "\n",
    "model = Sequential()\n",
    "# input: 100x100 images with 3 channels -> (3, 100, 100) tensors.\n",
    "# this applies 32 convolution filters of size 3x3 each.\n",
    "model.add(Convolution2D(4, 5, 5, border_mode='valid', input_shape=(1, 28, 28)))\n",
    "model.add(Activation('tanh'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Convolution2D(8, 3, 3))\n",
    "model.add(Activation('tanh'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# model.add(Convolution2D(64, 3, 3, border_mode='valid'))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Convolution2D(64, 3, 3))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "# Note: Keras does automatic shape inference.\n",
    "model.add(Dense(100))\n",
    "model.add(Activation('tanh'))\n",
    "\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "sgd = SGD(lr=0.05, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd,metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train, batch_size=100, nb_epoch=3,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
