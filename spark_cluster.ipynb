{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkConf,SparkContext\n",
    "from pyspark import rdd\n",
    "conf=SparkConf().setMaster(\"local[*]\").setAppName(\"First_APP\")\n",
    "sc=SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1|Toy Story (1995)|01-Jan-1995||http://us.imdb.com/M/title-exact?Toy%20Story%20(1995)|0|0|0|1|1|1|0|0|0|0|0|0|0|0|0|0|0|0|0']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies = sc.textFile('E:/machine_data/spark_test_data/ml-100k/u.item')\n",
    "movies.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------\n",
    "1.1 提取电影的题材标签\n",
    "-----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['unknown|0', 'Action|1', 'Adventure|2', 'Animation|3', \"Children's|4\"]\n",
      "unknown|0\n",
      "Action|1\n",
      "Adventure|2\n",
      "Animation|3\n",
      "Children's|4\n"
     ]
    }
   ],
   "source": [
    "genres = sc.textFile('E:/machine_data/spark_test_data/ml-100k/u.genre')\n",
    "print (genres.take(5))\n",
    "\n",
    "for line in genres.take(5):\n",
    "    print (line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "构造出的电影题材的编码字典: {'5': 'Comedy', '3': 'Animation', '16': 'Thriller', '1': 'Action', '2': 'Adventure', '11': 'Horror', '13': 'Mystery', '6': 'Crime', '9': 'Fantasy', '15': 'Sci-Fi', '4': \"Children's\", '17': 'War', '0': 'unknown', '10': 'Film-Noir', '18': 'Western', '12': 'Musical', '7': 'Documentary', '8': 'Drama', '14': 'Romance'}\n"
     ]
    }
   ],
   "source": [
    "#为电影题材编码\n",
    "genre_map = genres.filter(lambda x: len(x) > 0).map(lambda line : line.split('|')).map(lambda x:(x[1],x[0])).collectAsMap()\n",
    "print ('构造出的电影题材的编码字典:',genre_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "电影数据集的第一条数据: 1|Toy Story (1995)|01-Jan-1995||http://us.imdb.com/M/title-exact?Toy%20Story%20(1995)|0|0|0|1|1|1|0|0|0|0|0|0|0|0|0|0|0|0|0\n",
      "电影标题: ['Toy Story (1995)', 'GoldenEye (1995)', 'Four Rooms (1995)', 'Get Shorty (1995)', 'Copycat (1995)']\n",
      "电影的题材:\n",
      "[['0', '0', '0', '1', '1', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0'], ['0', '1', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0'], ['0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0'], ['0', '1', '0', '0', '0', '1', '0', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0'], ['0', '0', '0', '0', '0', '0', '1', '0', '1', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0']]\n"
     ]
    }
   ],
   "source": [
    "movies=sc.textFile('E:/machine_data/spark_test_data/ml-100k/u.item')\n",
    "print ('电影数据集的第一条数据:',movies.first())\n",
    "\n",
    "#查看电影的标题\n",
    "movies_title  = movies.map(lambda x: x.split('|')).map(lambda x: x[1])\n",
    "print ('电影标题:',movies_title.take(5))\n",
    "\n",
    "#查看电影的题材, 0表示不属于该题材, 1表示属于该题材\n",
    "movies_genre = movies.map(lambda x: x.split('|')).map(lambda x: x[5:])\n",
    "print ('电影的题材:')\n",
    "print (movies_genre.take(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "前5部电影的标题和相应的题材类型: [(1, \"Toy Story (1995),Animation,Children's,Comedy\"), (2, 'GoldenEye (1995),Action,Adventure,Thriller'), (3, 'Four Rooms (1995),Thriller'), (4, 'Get Shorty (1995),Action,Comedy,Drama'), (5, 'Copycat (1995),Crime,Drama,Thriller')]\n"
     ]
    }
   ],
   "source": [
    "#根据电影的题材编码字典genre_map，从上述结果可以知道，第一部电影属于Animation，Children's，Comedy题材.\n",
    "#下面看一看，各部电影各自属于哪种类型\n",
    "def func(rdd):\n",
    "    genres = rdd[5:]     #提取题材特征\n",
    "    genres_assigned = zip(genres, range(len(genres)))\n",
    "    index = []           #存储题材特征数值为1的特征索引号\n",
    "    for genre,idx in genres_assigned:\n",
    "        if genre=='1':\n",
    "            index.append(idx)\n",
    "    index_val = [genre_map[str(i)] for i in index]   #根据编码字典找出索引的相应题材名\n",
    "    index_val_str = ','.join(index_val)\n",
    "    return (int(rdd[0]),rdd[1]+','+index_val_str)\n",
    "titles_and_genres = movies.map(lambda x: x.split('|')).map(lambda x:func(x))\n",
    "print ('前5部电影的标题和相应的题材类型:',titles_and_genres.take(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------\n",
    "1.2 训练推荐模型\n",
    "--------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw data sample: [['196', '242', '3', '881250949'], ['186', '302', '3', '891717742'], ['22', '377', '1', '878887116']]\n",
      "rating data sample: [Rating(user=196, product=242, rating=3.0), Rating(user=186, product=302, rating=3.0), Rating(user=22, product=377, rating=1.0)]\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.recommendation import ALS\n",
    "from pyspark.mllib.recommendation import Rating\n",
    "\n",
    "raw_data = sc.textFile(\"E:/machine_data/spark_test_data/ml-100k/u.data\")\n",
    "#数据集u.data中四个字段分别表示用户ID, 电影ID, 评分, 时间戳\n",
    "print ('raw data sample:', raw_data.map(lambda x : x.split('\\t')).take(3))\n",
    "\n",
    "raw_ratings = raw_data.map(lambda x:x.split('\\t')[:3])\n",
    "ratings = raw_ratings.map(lambda x: Rating(x[0], x[1], x[2]))\n",
    "ratings.cache()\n",
    "print ('rating data sample:',ratings.take(3))\n",
    "\n",
    "#训练推荐模型\n",
    "als_model = ALS.train(ratings,50,5,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "productFeatures的第一条数据: [(4, array('d', [0.14387322962284088, 0.14869925379753113, -0.2368069589138031, -0.014290721155703068, -0.12111742049455643, -0.09147009998559952, -0.09890703856945038, -0.160025492310524, 0.5735045075416565, -0.13811266422271729, -0.05158152058720589, -0.2939601242542267, -0.22409386932849884, 0.09925245493650436, -0.08321025967597961, 0.053931429982185364, 0.10029783099889755, 0.20180019736289978, -0.21017244458198547, 0.18643592298030853, -0.3217353820800781, 0.18122124671936035, -0.2510859966278076, -0.15965671837329865, -0.2223781943321228, 0.3551555275917053, -0.34012436866760254, -0.14012393355369568, 0.1685008704662323, -0.42351454496383667, 0.14878679811954498, 0.3108901381492615, -0.23603136837482452, -0.006249609403312206, 0.0655541718006134, 0.13887828588485718, -0.17523664236068726, 0.3279019892215729, 0.5693528652191162, 0.062116168439388275, 0.11561039090156555, -0.22767698764801025, -0.2499641329050064, -0.06678327918052673, 0.7092862725257874, -0.35328158736228943, -0.05235150828957558, -0.12330348789691925, -0.009207281284034252, -0.15459616482257843]))]\n",
      "movie_factors的第一条数据: (4, DenseVector([0.1439, 0.1487, -0.2368, -0.0143, -0.1211, -0.0915, -0.0989, -0.16, 0.5735, -0.1381, -0.0516, -0.294, -0.2241, 0.0993, -0.0832, 0.0539, 0.1003, 0.2018, -0.2102, 0.1864, -0.3217, 0.1812, -0.2511, -0.1597, -0.2224, 0.3552, -0.3401, -0.1401, 0.1685, -0.4235, 0.1488, 0.3109, -0.236, -0.0062, 0.0656, 0.1389, -0.1752, 0.3279, 0.5694, 0.0621, 0.1156, -0.2277, -0.25, -0.0668, 0.7093, -0.3533, -0.0524, -0.1233, -0.0092, -0.1546]))\n",
      "user_factors的第一条数据: (4, DenseVector([0.2052, -0.0845, -0.4526, -0.3396, 0.161, -0.2126, -0.0686, -0.0626, 0.7701, -0.016, 0.3966, -0.0084, 0.0962, 0.3314, 0.2626, 0.2508, -0.0401, 0.6002, -0.2663, 0.382, -0.3969, 0.5081, -0.5235, -0.1317, -0.9678, 0.3636, -0.6031, -0.4802, -0.578, -0.6737, 0.7383, 0.2754, -0.1965, -0.0509, -0.1866, 0.548, -0.175, 0.6235, 0.3355, -0.5377, -0.0163, -0.0112, -0.2973, 0.3164, 0.4138, -0.3147, -0.3782, -0.5132, 0.5726, -0.8304]))\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.linalg import Vectors\n",
    "\n",
    "print ('productFeatures的第一条数据:',als_model.productFeatures().take(1))\n",
    "\n",
    "movie_factors = als_model.productFeatures().map(lambda kv: (kv[0],Vectors.dense(kv[1])))\n",
    "print ('movie_factors的第一条数据:',movie_factors.first())\n",
    "movie_vectors = movie_factors.map(lambda kv:kv[1])\n",
    "\n",
    "user_factors = als_model.userFeatures().map(lambda kv:(kv[0],Vectors.dense(kv[1])))\n",
    "print ('user_factors的第一条数据:',user_factors.first())\n",
    "user_vectors = user_factors.map(lambda kv:kv[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie factors mean: [ 0.01810578  0.01361871 -0.26275148 -0.02820166 -0.08286296 -0.02365649\n",
      " -0.05980769 -0.05652419  0.37480141 -0.10572021  0.00669056 -0.10592778\n",
      " -0.09410807  0.06773259  0.09730877  0.1649335   0.0750938   0.27019998\n",
      " -0.11571402  0.13084132 -0.18573318  0.08539546 -0.21946581 -0.10670612\n",
      " -0.25077449  0.31152667 -0.29765428 -0.14251722 -0.07079642 -0.47092918\n",
      "  0.16858506  0.12324861 -0.21732101 -0.05691996 -0.06235325  0.1645198\n",
      " -0.17009505  0.27837901  0.25721334 -0.06387119  0.10052837 -0.15240843\n",
      " -0.14915848  0.06086447  0.2678296  -0.14952754 -0.18920296 -0.16620377\n",
      "  0.05229777 -0.3870449 ]\n",
      "Movie factors variance: [ 0.05714024 -0.00647375 -0.45128601 -0.02788648 -0.17772425 -0.07894654\n",
      " -0.13689418 -0.13390418  0.59879596 -0.23217939  0.0178455  -0.13520601\n",
      " -0.18257522  0.15892019  0.10053736  0.2662292   0.21823402  0.40788709\n",
      " -0.20914878  0.20693222 -0.30303271  0.16251006 -0.41000196 -0.17527211\n",
      " -0.47297237  0.52718542 -0.44955608 -0.23641036 -0.11511373 -0.77826557\n",
      "  0.3090017   0.23869724 -0.34230693 -0.06496562 -0.11908887  0.27898317\n",
      " -0.25632022  0.44957472  0.44825578 -0.13167928  0.14230963 -0.20883144\n",
      " -0.20057105  0.08216026  0.46337948 -0.23785323 -0.2823845  -0.31322491\n",
      "  0.10682442 -0.6081051 ]\n",
      "User factors mean: [ 0.0264383   0.04074505  0.0291503   0.03016141  0.0321884   0.03277909\n",
      "  0.02847052  0.02592492  0.02957188  0.02760203  0.02369364  0.02512898\n",
      "  0.03167648  0.02838475  0.02647791  0.02598286  0.05756233  0.02597341\n",
      "  0.02065442  0.02330131  0.04948745  0.03081668  0.03091341  0.03816329\n",
      "  0.02777354  0.02620223  0.0361256   0.03109511  0.03272907  0.035658\n",
      "  0.0318704   0.03057591  0.03277487  0.02807376  0.0273017   0.03715314\n",
      "  0.03213291  0.02357061  0.04484925  0.01955814  0.03160079  0.02899979\n",
      "  0.02801478  0.03082325  0.04788003  0.02479125  0.02146656  0.03110198\n",
      "  0.03344199  0.03452041]\n",
      "User factors variance: [ 0.02959551  0.04576714  0.03219046  0.03807237  0.03458371  0.04354342\n",
      "  0.04250974  0.03246921  0.02980235  0.03360346  0.0341879   0.03288022\n",
      "  0.03571843  0.03352662  0.03458064  0.03882982  0.06633263  0.03733987\n",
      "  0.0282178   0.03562584  0.04972285  0.0375702   0.03208233  0.05154545\n",
      "  0.03320754  0.02767163  0.03688986  0.03530731  0.04147371  0.04508445\n",
      "  0.03927784  0.03731762  0.04055717  0.03190544  0.03324602  0.05286739\n",
      "  0.0401224   0.02890193  0.04264568  0.02838776  0.03730813  0.03839035\n",
      "  0.03362499  0.04399281  0.04357697  0.02944891  0.0350006   0.04195543\n",
      "  0.03990046  0.03029216]\n"
     ]
    }
   ],
   "source": [
    "#归一化\n",
    "from pyspark.mllib.linalg.distributed import RowMatrix\n",
    "\n",
    "moive_matrix = RowMatrix(movie_vectors)\n",
    "user_matrix = RowMatrix(user_vectors)\n",
    "\n",
    "\n",
    "from pyspark.mllib.stat import MultivariateStatisticalSummary\n",
    "desc_moive_matrix = MultivariateStatisticalSummary(moive_matrix.rows)\n",
    "desc_user_matrix = MultivariateStatisticalSummary(user_matrix.rows)\n",
    "print ('Movie factors mean:',desc_moive_matrix.mean())\n",
    "print ('Movie factors variance:',desc_user_matrix.mean())\n",
    "print ('User factors mean:',desc_moive_matrix.variance())\n",
    "print ('User factors variance:',desc_user_matrix.variance())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.143873229623,0.148699253798,-0.236806958914,-0.0142907211557,-0.121117420495,-0.0914700999856,-0.0989070385695,-0.160025492311,0.573504507542,-0.138112664223,-0.0515815205872,-0.293960124254,-0.224093869328,0.0992524549365,-0.083210259676,0.0539314299822,0.100297830999,0.201800197363,-0.210172444582,0.18643592298,-0.32173538208,0.181221246719,-0.251085996628,-0.159656718373,-0.222378194332,0.355155527592,-0.340124368668,-0.140123933554,0.168500870466,-0.423514544964,0.14878679812,0.310890138149,-0.236031368375,-0.00624960940331,0.0655541718006,0.138878285885,-0.175236642361,0.327901989222,0.569352865219,0.0621161684394,0.115610390902,-0.227676987648,-0.249964132905,-0.0667832791805,0.709286272526,-0.353281587362,-0.0523515082896,-0.123303487897,-0.00920728128403,-0.154596164823]\n"
     ]
    }
   ],
   "source": [
    "print (moive_matrix.rows.first())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "----------------------\n",
    "2 训练聚类模型\n",
    "----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda1\\lib\\site-packages\\pyspark\\mllib\\clustering.py:347: UserWarning: The param `runs` has no effect since Spark 2.0.0.\n",
      "  warnings.warn(\"The param `runs` has no effect since Spark 2.0.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "对前十个样本的预测标签为:3,3,3,2,4,2,3,2,1,0\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.clustering import KMeans\n",
    "num_clusters = 5\n",
    "num_iterations = 20\n",
    "num_runs =3\n",
    "movie_cluster_model = KMeans.train(movie_vectors,num_clusters, num_iterations, num_runs)\n",
    "movie_cluster_model_coverged = KMeans.train(movie_vectors,num_clusters,100)\n",
    "user_cluster_model = KMeans.train(user_vectors,num_clusters,num_iterations, num_runs)\n",
    "predictions = movie_cluster_model.predict(movie_vectors)\n",
    "print ('对前十个样本的预测标签为:'+\",\".join([str(i) for i in predictions.take(10)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movie_factors的第一条数据: (4, DenseVector([0.1439, 0.1487, -0.2368, -0.0143, -0.1211, -0.0915, -0.0989, -0.16, 0.5735, -0.1381, -0.0516, -0.294, -0.2241, 0.0993, -0.0832, 0.0539, 0.1003, 0.2018, -0.2102, 0.1864, -0.3217, 0.1812, -0.2511, -0.1597, -0.2224, 0.3552, -0.3401, -0.1401, 0.1685, -0.4235, 0.1488, 0.3109, -0.236, -0.0062, 0.0656, 0.1389, -0.1752, 0.3279, 0.5694, 0.0621, 0.1156, -0.2277, -0.25, -0.0668, 0.7093, -0.3533, -0.0524, -0.1233, -0.0092, -0.1546]))\n",
      "========================\n",
      "titles_and_genres的第一条数据: (1, \"Toy Story (1995),Animation,Children's,Comedy\")\n",
      "========================\n",
      "titles_factors的第一条数据: (1536, ('Aiqing wansui (1994),Drama', DenseVector([0.155, -0.0353, -0.2588, 0.0703, -0.0347, 0.182, 0.2314, 0.1831, 0.5017, -0.0612, -0.095, 0.0282, 0.0526, 0.1227, 0.2289, -0.0858, -0.4768, 0.2053, 0.1029, 0.164, -0.4535, 0.2508, -0.2892, 0.2077, -0.3039, 0.5213, -0.4001, -0.179, 0.0578, -0.3276, 0.0444, -0.0119, -0.3677, -0.0436, 0.0081, 0.093, -0.5312, 0.2834, 0.5837, 0.0817, 0.0533, 0.0906, -0.3159, -0.1285, 0.7609, -0.1049, -0.3015, -0.1349, -0.1342, -0.6679])))\n"
     ]
    }
   ],
   "source": [
    "print ('movie_factors的第一条数据:',movie_factors.first())\n",
    "print ('========================')\n",
    "print ('titles_and_genres的第一条数据:',titles_and_genres.first())\n",
    "\n",
    "titles_factors = titles_and_genres.join(movie_factors)\n",
    "print ('========================')\n",
    "print ('titles_factors的第一条数据:',titles_factors.first())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "电影1536的题材类型是Aiqing wansui (1994),Drama,聚类模型预测的标签是2,与聚类所属类别中心的距离是0.918217802304\n",
      "电影1026的题材类型是Lay of the Land, The (1997),Comedy,Drama,聚类模型预测的标签是1,与聚类所属类别中心的距离是1.41027486856\n",
      "电影516的题材类型是Local Hero (1983),Comedy,聚类模型预测的标签是2,与聚类所属类别中心的距离是1.15395962633\n",
      "电影6的题材类型是Shanghai Triad (Yao a yao yao dao waipo qiao) (1995),Drama,聚类模型预测的标签是4,与聚类所属类别中心的距离是2.33645184929\n",
      "电影1032的题材类型是Little Big League (1994),Children's,Comedy,聚类模型预测的标签是0,与聚类所属类别中心的距离是1.10033642729\n"
     ]
    }
   ],
   "source": [
    "#对每个电影计算其特征向量与类簇中心向量的距离\n",
    "def func2(rdd):\n",
    "    id,(name_genres,vec) = rdd\n",
    "    pred = movie_cluster_model.predict(vec)\n",
    "    cluster_center = movie_cluster_model.clusterCenters[pred]\n",
    "    cluster_center_vec = Vectors.dense(cluster_center)\n",
    "    dist = vec.squared_distance(cluster_center_vec)\n",
    "    return u'电影' + str(id) + u'的题材类型是' + name_genres + ',' + u'聚类模型预测的标签是' + str(pred)+ ',' + \\\n",
    "           u'与聚类所属类别中心的距离是' + str(dist)\n",
    "\n",
    "movies_assigned = titles_factors.map(lambda x:func2(x))  \n",
    "for i in movies_assigned.take(5):\n",
    "    print (i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------\n",
    "3 评估聚类模型的性能\n",
    "--------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1 内部评价指标\n",
    "\n",
    " 通用的内部评价指标包括WCSS（我们之前提过的K-元件的目标函数）、Davies-Bouldin指数、Dunn指数和轮廓系数（silhouette coefficient）。所有这些度量指标都是使类簇内部的样本距离尽可能接近，不同类簇的样本相对较远。\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "3.2 外部评价指标\n",
    "\n",
    " 因为聚类被认为是无监督分类，如果有一些带标注的数据，便可以用这些标签来评估聚类模型。可以使用聚类模型预测类簇（类标签），使用分类模型中类似的方法评估预测值和真实标签的误差（即真假阳性率和真假阴性率）。\n",
    " 具体方法包括Rand measure、F-measure、雅卡尔系数（Jaccard index）等。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WCSS for movies: 2173.614888\n",
      "WCSS for users: 1492.128578\n"
     ]
    }
   ],
   "source": [
    "movie_cost = movie_cluster_model.computeCost(movie_vectors)\n",
    "user_cost = user_cluster_model.computeCost(user_vectors)\n",
    "print (\"WCSS for movies: %f\"%movie_cost)\n",
    "print (\"WCSS for users: %f\"%user_cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------\n",
    "4 聚类模型参数调优\n",
    "----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "不同于以往的模型，K-均值模型只有一个可以调的参数，就是K，即类中心数目。通过交叉验证选择K\n",
    " 类似分类和回归模型，我们可以应用交叉验证来选择模型最优的类中心数目。这和监督学习的过程一样。需要将数据集分割为训练集和测试集，然后在训练集上训练模型，在测试集上评估感兴趣的指标的性能。如下代码用60/40划分得到训练集和测试集，并使用MLlib内置的WCSS类方法评估聚类模型的性能："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda1\\lib\\site-packages\\pyspark\\mllib\\clustering.py:347: UserWarning: The param `runs` has no effect since Spark 2.0.0.\n",
      "  warnings.warn(\"The param `runs` has no effect since Spark 2.0.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WCSS for k=2 : 782.136925\n",
      "WCSS for k=3 : 773.803139\n",
      "WCSS for k=4 : 774.105182\n",
      "WCSS for k=5 : 769.060786\n",
      "WCSS for k=10 : 768.085290\n",
      "WCSS for k=20 : 767.425721\n",
      "WCSS for k=30 : 766.717561\n"
     ]
    }
   ],
   "source": [
    "train_test_split_movies = movie_vectors.randomSplit([0.6,0.4],123)\n",
    "train_movies = train_test_split_movies[0]\n",
    "test_movies = train_test_split_movies[1]\n",
    "for k in [2,3,4,5,10,20,30]:\n",
    "    k_model = KMeans.train(train_movies, num_iterations, k, num_runs)\n",
    "    cost = k_model.computeCost(test_movies)\n",
    "    print ('WCSS for k=%d : %f'%(k,cost))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " 从结果可以看出，随着类中心数目增加，WCSS值会出现下降，然后又开始增大。另外一个现象，K-均值在交叉验证的情况，WCSS随着K的增大持续减小，但是达到某个值后，下降的速率突然会变得很平缓。这时的K通常为最优的K值（这称为拐点）。根据预测结果，我们选择最优的K=10??。需要说明是，模型计算的类簇需要人工解释（比如前面提到的电影或者顾客聚类的例子），并且会影响K的选择。尽管较大的K值从数学的角度可以得到更优的解，但是类簇太多就会变得难以理解和解释。为了实验的完整性，我们还计算了用户聚类在交叉验证下的性能："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda1\\lib\\site-packages\\pyspark\\mllib\\clustering.py:347: UserWarning: The param `runs` has no effect since Spark 2.0.0.\n",
      "  warnings.warn(\"The param `runs` has no effect since Spark 2.0.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WCSS for k=2 : 574.152900\n",
      "WCSS for k=3 : 574.217316\n",
      "WCSS for k=4 : 569.361084\n",
      "WCSS for k=5 : 570.712942\n",
      "WCSS for k=10 : 573.570436\n",
      "WCSS for k=20 : 578.410961\n"
     ]
    }
   ],
   "source": [
    "train_test_split_movies = user_vectors.randomSplit([0.6,0.4],123)\n",
    "train_users = train_test_split_movies[0]\n",
    "test_users = train_test_split_movies[1]\n",
    "for k in [2,3,4,5,10,20]:\n",
    "    k_model = KMeans.train(train_users,num_iterations,k,num_runs)\n",
    "    cost = k_model.computeCost(test_users)\n",
    "    print ('WCSS for k=%d : %f'%(k,cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
