{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import time\n",
    "import warnings\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import newaxis\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename='E:/machine_data/LSTM-Neural-Network-for-Time-Series-Prediction-master/sp500.csv'\n",
    "seq_len=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open(filename, 'rb').read()\n",
    "data = f.decode().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'1455.219971\\n1399.420044\\n1402.1'\n",
      "['1455.219971', '1399.420044', '1402.109985']\n"
     ]
    }
   ],
   "source": [
    "print (f[0:30])\n",
    "print (data[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result len: 4121\n",
      "result shape: (4121, 51)\n",
      "51\n",
      "['1455.219971', '1399.420044', '1402.109985', '1403.449951', '1441.469971', '1457.599976', '1438.560059', '1432.25', '1449.680054', '1465.150024', '1455.140015', '1455.900024', '1445.569946', '1441.359985', '1401.530029', '1410.030029', '1404.089966', '1398.560059', '1360.160034', '1394.459961', '1409.280029', '1409.119995', '1424.969971', '1424.369995', '1424.23999', '1441.719971', '1411.709961', '1416.829956', '1387.119995', '1389.939941', '1402.050049', '1387.670044', '1388.26001', '1346.089966', '1352.170044', '1360.689941', '1353.430054', '1333.359985', '1348.050049', '1366.420044', '1379.189941', '1381.76001', '1409.170044', '1391.280029', '1355.619995', '1366.699951', '1401.689941', '1395.069946', '1383.619995', '1359.150024', '1392.140015']\n"
     ]
    }
   ],
   "source": [
    "sequence_length = seq_len + 1\n",
    "result = []\n",
    "for index in range(len(data) - sequence_length):\n",
    "    result.append(data[index: index + sequence_length])  #得到长度为seq_len+1的向量，最后一个作为label\n",
    "\n",
    "print('result len:',len(result))   #4121\n",
    "print('result shape:',np.array(result).shape)  #（4121,51）\n",
    "print(len(result[0]))\n",
    "print(result[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type (result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result = np.array(result)\n",
    "#划分train、test\n",
    "row = round(0.9 * result.shape[0])\n",
    "train = result[:row, :]\n",
    "np.random.shuffle(train)\n",
    "x_train = train[:, :-1]\n",
    "y_train = train[:, -1]\n",
    "x_test = result[row:, :-1]\n",
    "y_test = result[row:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3709\n"
     ]
    }
   ],
   "source": [
    "print (row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3709, 50)\n"
     ]
    }
   ],
   "source": [
    "print (x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (3709, 50, 1)\n",
      "y_train shape: (3709,)\n",
      "X_test shape: (412, 50, 1)\n",
      "y_test shape: (412,)\n"
     ]
    }
   ],
   "source": [
    "x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
    "x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))  \n",
    "\n",
    "print('X_train shape:',x_train.shape)  #(3709L, 50L, 1L)\n",
    "print('y_train shape:',y_train.shape)  #(3709L,)\n",
    "print('X_test shape:',x_test.shape)    #(412L, 50L, 1L)\n",
    "print('y_test shape:',y_test.shape)    #(412L,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 1)\n",
      "[['1977.650024']\n",
      " ['1963.709961']\n",
      " ['1972.829956']\n",
      " ['1964.680054']\n",
      " ['1967.569946']\n",
      " ['1977.099976']\n",
      " ['1973.280029']\n",
      " ['1981.569946']\n",
      " ['1958.119995']\n",
      " ['1978.219971']\n",
      " ['1973.630005']\n",
      " ['1983.530029']\n",
      " ['1987.01001']\n",
      " ['1987.97998']\n",
      " ['1978.339966']\n",
      " ['1978.910034']\n",
      " ['1969.949951']\n",
      " ['1970.069946']\n",
      " ['1930.670044']\n",
      " ['1925.150024']\n",
      " ['1938.98999']\n",
      " ['1920.209961']\n",
      " ['1920.23999']\n",
      " ['1909.569946']\n",
      " ['1931.589966']\n",
      " ['1936.920044']\n",
      " ['1933.75']\n",
      " ['1946.719971']\n",
      " ['1955.180054']\n",
      " ['1955.060059']\n",
      " ['1971.73999']\n",
      " ['1981.599976']\n",
      " ['1986.51001']\n",
      " ['1992.369995']\n",
      " ['1988.400024']\n",
      " ['1997.920044']\n",
      " ['2000.02002']\n",
      " ['2000.119995']\n",
      " ['1996.73999']\n",
      " ['2003.369995']\n",
      " ['2002.280029']\n",
      " ['2000.719971']\n",
      " ['1997.650024']\n",
      " ['2007.709961']\n",
      " ['2001.540039']\n",
      " ['1988.439941']\n",
      " ['1995.689941']\n",
      " ['1997.449951']\n",
      " ['1985.540039']\n",
      " ['1984.130005']]\n"
     ]
    }
   ],
   "source": [
    "print (x_train[0].shape)\n",
    "print (x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(filename, seq_len):\n",
    "    f = open(filename, 'rb').read()\n",
    "    data = f.decode().split('\\n')\n",
    "\n",
    "    print('data len:',len(data))       #4172\n",
    "    print('sequence len:',seq_len)     #50\n",
    "\n",
    "    sequence_length = seq_len + 1\n",
    "    result = []\n",
    "    for index in range(len(data) - sequence_length):\n",
    "        result.append(data[index: index + sequence_length])  #得到长度为seq_len+1的向量，最后一个作为label\n",
    "\n",
    "    print('result len:',len(result))   #4121\n",
    "    print('result shape:',np.array(result).shape)  #（4121,51）\n",
    "\n",
    "    result = np.array(result)\n",
    "\n",
    "    #划分train、test\n",
    "    row = round(0.9 * result.shape[0])\n",
    "    train = result[:row, :]\n",
    "    np.random.shuffle(train)\n",
    "    x_train = train[:, :-1]\n",
    "    y_train = train[:, -1]\n",
    "    x_test = result[row:, :-1]\n",
    "    y_test = result[row:, -1]\n",
    "\n",
    "    x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
    "    x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))  \n",
    "\n",
    "    print('X_train shape:',x_train.shape)  #(3709L, 50L, 1L)\n",
    "    print('y_train shape:',y_train.shape)  #(3709L,)\n",
    "    print('X_test shape:',x_test.shape)    #(412L, 50L, 1L)\n",
    "    print('y_test shape:',y_test.shape)    #(412L,)\n",
    "\n",
    "    return [x_train, y_train, x_test, y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data len: 4172\n",
      "sequence len: 50\n",
      "result len: 4121\n",
      "result shape: (4121, 51)\n",
      "X_train shape: (3709, 50, 1)\n",
      "y_train shape: (3709,)\n",
      "X_test shape: (412, 50, 1)\n",
      "y_test shape: (412,)\n"
     ]
    }
   ],
   "source": [
    "[x_train, y_train, x_test, y_test]=load_data('E:/machine_data/LSTM-Neural-Network-for-Time-Series-Prediction-master/sp500.csv', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_model(layers):  #layers [1,50,100,1]\n",
    "    model = Sequential()\n",
    "\n",
    "    #Stack LSTM\n",
    "    model.add(LSTM(input_dim=layers[0],output_dim=layers[1],return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(LSTM(layers[2],return_sequences=False))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Dense(output_dim=layers[3]))\n",
    "    model.add(Activation(\"linear\"))\n",
    "\n",
    "    start = time.time()\n",
    "    model.compile(loss=\"mse\", optimizer=\"rmsprop\",metrics=['accuracy'])\n",
    "    print(\"Compilation Time : \", time.time() - start)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_point_by_point(model, data):\n",
    "    predicted = model.predict(data)\n",
    "    print('predicted shape:',np.array(predicted).shape)  #(412L,1L)\n",
    "    predicted = np.reshape(predicted, (predicted.size,))\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda1\\lib\\site-packages\\ipykernel\\__main__.py:5: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "D:\\anaconda1\\lib\\site-packages\\ipykernel\\__main__.py:5: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(units=50, input_shape=(None, 1), return_sequences=True)`\n",
      "D:\\anaconda1\\lib\\site-packages\\ipykernel\\__main__.py:11: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=1)`\n",
      "D:\\anaconda1\\lib\\site-packages\\keras\\models.py:837: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compilation Time :  0.03515338897705078\n",
      "Train on 3523 samples, validate on 186 samples\n",
      "Epoch 1/1\n",
      "3523/3523 [==============================] - 7s - loss: 1689739.1193 - acc: 0.0000e+00 - val_loss: 1777554.3750 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d2d707a668>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = build_model([1, 50, 100, 1])\n",
    "\n",
    "model.fit(x_train,y_train,batch_size=512,epochs=1,validation_split=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted shape: (412, 1)\n",
      "point_by_point_predictions shape: (412,)\n"
     ]
    }
   ],
   "source": [
    "point_by_point_predictions = predict_point_by_point(model, x_test)\n",
    "print('point_by_point_predictions shape:',np.array(point_by_point_predictions).shape)  #(412L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_results(predicted_data, true_data, filename):\n",
    "    fig = plt.figure(facecolor='white')\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.plot(true_data, label='True Data')\n",
    "    plt.plot(predicted_data, label='Prediction')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    plt.savefig(filename+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_results(point_by_point_predictions,y_test,'point_by_point_predictions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 下面是总代码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Loading data... \n",
      "data len: 4172\n",
      "sequence len: 50\n",
      "result len: 4121\n",
      "result shape: (4121, 51)\n",
      "[['1455.219971', '1399.420044', '1402.109985', '1403.449951', '1441.469971', '1457.599976', '1438.560059', '1432.25', '1449.680054', '1465.150024', '1455.140015', '1455.900024', '1445.569946', '1441.359985', '1401.530029', '1410.030029', '1404.089966', '1398.560059', '1360.160034', '1394.459961', '1409.280029', '1409.119995', '1424.969971', '1424.369995', '1424.23999', '1441.719971', '1411.709961', '1416.829956', '1387.119995', '1389.939941', '1402.050049', '1387.670044', '1388.26001', '1346.089966', '1352.170044', '1360.689941', '1353.430054', '1333.359985', '1348.050049', '1366.420044', '1379.189941', '1381.76001', '1409.170044', '1391.280029', '1355.619995', '1366.699951', '1401.689941', '1395.069946', '1383.619995', '1359.150024', '1392.140015']]\n",
      "[[0.0, -0.03834466823710192, -0.03649619099406931, -0.03557539137153576, -0.009448743333663301, 0.001635495009297161, -0.011448380541775882, -0.01578453529895929, -0.003806927550748962, 0.006823747060848984, -5.494427068997165e-05, 0.0004673197272937468, -0.006631317046431495, -0.009524323659793943, -0.03689472593143783, -0.031053684597900588, -0.035135585010467096, -0.03893563387606924, -0.0653234142565241, -0.04175314468660485, -0.03156907059791858, -0.03167904297542101, -0.02078723533405935, -0.021199527641721727, -0.0212888646509648, -0.00927694800032397, -0.029899266686190917, -0.026380901695308046, -0.04679703230928234, -0.044859218057006656, -0.03653737789446543, -0.046419048904050575, -0.046013635281535015, -0.07499210234519249, -0.07081398623823587, -0.06495927205770868, -0.06994813088639229, -0.08373990766238593, -0.07364516989576142, -0.06102165223789391, -0.05224641739059799, -0.050480313948357725, -0.03164465023686791, -0.043938334598350504, -0.06844324431003834, -0.06082930537241782, -0.036784837390058, -0.04133397438097686, -0.04920216697603308, -0.06601747427502835, -0.04334736827220198]]\n",
      "normalise_windows result shape: (4121, 51)\n",
      "X_train shape: (3709, 50, 1)\n",
      "y_train shape: (3709,)\n",
      "X_test shape: (412, 50, 1)\n",
      "y_test shape: (412,)\n",
      "> Data Loaded. Compiling...\n",
      "Compilation Time :  0.034090518951416016\n",
      "Train on 3523 samples, validate on 186 samples\n",
      "Epoch 1/1\n",
      "3523/3523 [==============================] - 8s - loss: 0.0021 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
      "multiple_predictions shape: (8, 50)\n",
      "full_predictions shape: (412,)\n",
      "predicted shape: (412, 1)\n",
      "point_by_point_predictions shape: (412,)\n",
      "Training duration (s) :  17.924267292022705\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import time\n",
    "import warnings\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import newaxis\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import Sequential\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def load_data(filename, seq_len, normalise_window):\n",
    "    f = open(filename, 'rb').read()\n",
    "    data = f.decode().split('\\n')\n",
    "\n",
    "    print('data len:',len(data))\n",
    "    print('sequence len:',seq_len)\n",
    "\n",
    "    sequence_length = seq_len + 1\n",
    "    result = []\n",
    "    for index in range(len(data) - sequence_length):\n",
    "        result.append(data[index: index + sequence_length])  #得到长度为seq_len+1的向量，最后一个作为label\n",
    "\n",
    "    print('result len:',len(result))\n",
    "    print('result shape:',np.array(result).shape)\n",
    "    print(result[:1])\n",
    "\n",
    "    if normalise_window:\n",
    "        result = normalise_windows(result)\n",
    "\n",
    "    print(result[:1])\n",
    "    print('normalise_windows result shape:',np.array(result).shape)\n",
    "\n",
    "    result = np.array(result)\n",
    "\n",
    "    #划分train、test\n",
    "    row = round(0.9 * result.shape[0])\n",
    "    train = result[:row, :]\n",
    "    np.random.shuffle(train)\n",
    "    x_train = train[:, :-1]\n",
    "    y_train = train[:, -1]\n",
    "    x_test = result[row:, :-1]\n",
    "    y_test = result[row:, -1]\n",
    "\n",
    "    x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
    "    x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))\n",
    "\n",
    "    return [x_train, y_train, x_test, y_test]\n",
    "\n",
    "def normalise_windows(window_data):\n",
    "    normalised_data = []\n",
    "    for window in window_data:   #window shape (sequence_length L ,)  即(51L,)\n",
    "        normalised_window = [((float(p) / float(window[0])) - 1) for p in window]\n",
    "        normalised_data.append(normalised_window)\n",
    "    return normalised_data\n",
    "\n",
    "def build_model(layers):  #layers [1,50,100,1]\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(LSTM(input_dim=layers[0],output_dim=layers[1],return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(LSTM(layers[2],return_sequences=False))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Dense(output_dim=layers[3]))\n",
    "    model.add(Activation(\"linear\"))\n",
    "\n",
    "    start = time.time()\n",
    "    model.compile(loss=\"mse\", optimizer=\"rmsprop\",metrics=['accuracy'])\n",
    "    print(\"Compilation Time : \", time.time() - start)\n",
    "    return model\n",
    "\n",
    "#直接全部预测\n",
    "def predict_point_by_point(model, data):\n",
    "    predicted = model.predict(data)\n",
    "    print('predicted shape:',np.array(predicted).shape)  #(412L,1L)\n",
    "    predicted = np.reshape(predicted, (predicted.size,))\n",
    "    return predicted\n",
    "\n",
    "#滚动预测\n",
    "def predict_sequence_full(model, data, window_size):  #data X_test\n",
    "    curr_frame = data[0]  #(50L,1L)\n",
    "    predicted = []\n",
    "    for i in range(len(data)):\n",
    "        #x = np.array([[[1],[2],[3]], [[4],[5],[6]]])  x.shape (2, 3, 1) x[0,0] = array([1])  x[:,np.newaxis,:,:].shape  (2, 1, 3, 1)\n",
    "        predicted.append(model.predict(curr_frame[newaxis,:,:])[0,0])  #np.array(curr_frame[newaxis,:,:]).shape (1L,50L,1L)\n",
    "        curr_frame = curr_frame[1:]\n",
    "        curr_frame = np.insert(curr_frame, [window_size-1], predicted[-1], axis=0)   #numpy.insert(arr, obj, values, axis=None)\n",
    "    return predicted\n",
    "\n",
    "def predict_sequences_multiple(model, data, window_size, prediction_len):  #window_size = seq_len\n",
    "    prediction_seqs = []\n",
    "    for i in range(int(len(data)/prediction_len)):\n",
    "        curr_frame = data[i*prediction_len]\n",
    "        predicted = []\n",
    "        for j in range(prediction_len):\n",
    "            predicted.append(model.predict(curr_frame[newaxis,:,:])[0,0])\n",
    "            curr_frame = curr_frame[1:]\n",
    "            curr_frame = np.insert(curr_frame, [window_size-1], predicted[-1], axis=0)\n",
    "        prediction_seqs.append(predicted)\n",
    "    return prediction_seqs\n",
    "\n",
    "def plot_results(predicted_data, true_data, filename):\n",
    "    fig = plt.figure(facecolor='white')\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.plot(true_data, label='True Data')\n",
    "    plt.plot(predicted_data, label='Prediction')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    plt.savefig(filename+'.png')\n",
    "\n",
    "def plot_results_multiple(predicted_data, true_data, prediction_len):\n",
    "    fig = plt.figure(facecolor='white')\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.plot(true_data, label='True Data')\n",
    "    #Pad the list of predictions to shift it in the graph to it's correct start\n",
    "    for i, data in enumerate(predicted_data):\n",
    "        padding = [None for p in range(i * prediction_len)]\n",
    "        plt.plot(padding + data, label='Prediction')\n",
    "        plt.legend()\n",
    "    plt.show()\n",
    "    plt.savefig('plot_results_multiple.png')\n",
    "\n",
    "if __name__=='__main__':\n",
    "    global_start_time = time.time()\n",
    "    epochs  = 1\n",
    "    seq_len = 50\n",
    "\n",
    "    print('> Loading data... ')\n",
    "\n",
    "    X_train, y_train, X_test, y_test = load_data('E:/machine_data/LSTM-Neural-Network-for-Time-Series-Prediction-master/sp500.csv', seq_len, True)\n",
    "\n",
    "    print('X_train shape:',X_train.shape)  #(3709L, 50L, 1L)\n",
    "    print('y_train shape:',y_train.shape)  #(3709L,)\n",
    "    print('X_test shape:',X_test.shape)    #(412L, 50L, 1L)\n",
    "    print('y_test shape:',y_test.shape)    #(412L,)\n",
    "\n",
    "    print('> Data Loaded. Compiling...')\n",
    "\n",
    "    model = build_model([1, 50, 100, 1])\n",
    "\n",
    "    model.fit(X_train,y_train,batch_size=512,nb_epoch=epochs,validation_split=0.05)\n",
    "\n",
    "    multiple_predictions = predict_sequences_multiple(model, X_test, seq_len, prediction_len=50)\n",
    "    print('multiple_predictions shape:',np.array(multiple_predictions).shape)   #(8L,50L)\n",
    "\n",
    "    full_predictions = predict_sequence_full(model, X_test, seq_len)\n",
    "    print('full_predictions shape:',np.array(full_predictions).shape)    #(412L,)\n",
    "\n",
    "    point_by_point_predictions = predict_point_by_point(model, X_test)\n",
    "    print('point_by_point_predictions shape:',np.array(point_by_point_predictions).shape)  #(412L)\n",
    "\n",
    "    print('Training duration (s) : ', time.time() - global_start_time)\n",
    "\n",
    "    plot_results_multiple(multiple_predictions, y_test, 50)\n",
    "    plot_results(full_predictions,y_test,'full_predictions')\n",
    "    plot_results(point_by_point_predictions,y_test,'point_by_point_predictions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.        ]\n",
      " [-0.01070544]\n",
      " [-0.00655728]\n",
      " [-0.0165247 ]\n",
      " [-0.02102908]\n",
      " [-0.01115506]\n",
      " [-0.00427532]\n",
      " [ 0.0057006 ]\n",
      " [ 0.01038308]\n",
      " [ 0.00885622]\n",
      " [ 0.01274136]\n",
      " [ 0.01291946]\n",
      " [ 0.00947545]\n",
      " [ 0.01593094]\n",
      " [ 0.01691499]\n",
      " [ 0.0107394 ]\n",
      " [ 0.01983306]\n",
      " [ 0.02158908]\n",
      " [ 0.01457369]\n",
      " [ 0.01583764]\n",
      " [ 0.01562557]\n",
      " [ 0.01342852]\n",
      " [ 0.01873884]\n",
      " [ 0.01634659]\n",
      " [ 0.01864543]\n",
      " [ 0.02126673]\n",
      " [ 0.0235316 ]\n",
      " [ 0.02724712]\n",
      " [ 0.03233687]\n",
      " [ 0.03160735]\n",
      " [ 0.02949511]\n",
      " [ 0.02972417]\n",
      " [ 0.01856911]\n",
      " [ 0.01079873]\n",
      " [ 0.01005223]\n",
      " [ 0.01928165]\n",
      " [ 0.01782261]\n",
      " [ 0.01059515]\n",
      " [ 0.01323333]\n",
      " [ 0.02218284]\n",
      " [ 0.01365747]\n",
      " [ 0.01614301]\n",
      " [ 0.0280106 ]\n",
      " [ 0.03444062]\n",
      " [ 0.0367904 ]\n",
      " [ 0.03770662]\n",
      " [ 0.0404296 ]\n",
      " [ 0.04163422]\n",
      " [ 0.03587428]\n",
      " [ 0.04284722]]\n"
     ]
    }
   ],
   "source": [
    "print (X_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 某家店的某顾客的历史消费的时间推测该顾客前下次来店的时间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def create_interval_dataset(dataset, look_back):\n",
    "    \"\"\"\n",
    "    :param dataset: input array of time intervals\n",
    "    :param look_back: each training set feature length\n",
    "    :return: convert an array of values into a dataset matrix.\n",
    "    \"\"\"\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset) - look_back):\n",
    "        dataX.append(dataset[i:i+look_back])\n",
    "        dataY.append(dataset[i+look_back])\n",
    "    return np.asarray(dataX), np.asarray(dataY)\n",
    "\n",
    "df = pd.read_csv(\"path-to-your-time-interval-file\")    \n",
    "dataset_init = np.asarray(df)    # if only 1 column\n",
    "dataX, dataY = create_interval_dataset(dataset, lookback=3)    # look back if the training set sequence length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from keras.models import Sequential, model_from_json\n",
    "from keras.layers import Dense, LSTM, Dropout\n",
    "\n",
    "class NeuralNetwork():\n",
    "    def __init__(self, **kwargs):\n",
    "        \"\"\"\n",
    "        :param **kwargs: output_dim=4: output dimension of LSTM layer; activation_lstm='tanh': activation function for LSTM layers; activation_dense='relu': activation function for Dense layer; activation_last='sigmoid': activation function for last layer; drop_out=0.2: fraction of input units to drop; np_epoch=10, the number of epoches to train the model. epoch is one forward pass and one backward pass of all the training examples; batch_size=32: number of samples per gradient update. The higher the batch size, the more memory space you'll need; loss='mean_square_error': loss function; optimizer='rmsprop'\n",
    "        \"\"\"\n",
    "        self.output_dim = kwargs.get('output_dim', 8)\n",
    "        self.activation_lstm = kwargs.get('activation_lstm', 'relu')\n",
    "        self.activation_dense = kwargs.get('activation_dense', 'relu')\n",
    "        self.activation_last = kwargs.get('activation_last', 'softmax')    # softmax for multiple output\n",
    "        self.dense_layer = kwargs.get('dense_layer', 2)     # at least 2 layers\n",
    "        self.lstm_layer = kwargs.get('lstm_layer', 2)\n",
    "        self.drop_out = kwargs.get('drop_out', 0.2)\n",
    "        self.nb_epoch = kwargs.get('nb_epoch', 10)\n",
    "        self.batch_size = kwargs.get('batch_size', 100)\n",
    "        self.loss = kwargs.get('loss', 'categorical_crossentropy')\n",
    "        self.optimizer = kwargs.get('optimizer', 'rmsprop')\n",
    "\n",
    "        def NN_model(self, trainX, trainY, testX, testY):\n",
    "        \"\"\"\n",
    "        :param trainX: training data set\n",
    "        :param trainY: expect value of training data\n",
    "        :param testX: test data set\n",
    "        :param testY: epect value of test data\n",
    "        :return: model after training\n",
    "        \"\"\"\n",
    "        print \"Training model is LSTM network!\"\n",
    "        input_dim = trainX[1].shape[1]\n",
    "        output_dim = trainY.shape[1] # one-hot label\n",
    "        # print predefined parameters of current model:\n",
    "        model = Sequential()\n",
    "        # applying a LSTM layer with x dim output and y dim input. Use dropout parameter to avoid overfitting\n",
    "        model.add(LSTM(output_dim=self.output_dim,\n",
    "                       input_dim=input_dim,\n",
    "                       activation=self.activation_lstm,\n",
    "                       dropout_U=self.drop_out,\n",
    "                       return_sequences=True))\n",
    "        for i in range(self.lstm_layer-2):\n",
    "            model.add(LSTM(output_dim=self.output_dim,\n",
    "                       input_dim=self.output_dim,\n",
    "                       activation=self.activation_lstm,\n",
    "                       dropout_U=self.drop_out,\n",
    "                       return_sequences=True))\n",
    "        # argument return_sequences should be false in last lstm layer to avoid input dimension incompatibility with dense layer\n",
    "        model.add(LSTM(output_dim=self.output_dim,\n",
    "                       input_dim=self.output_dim,\n",
    "                       activation=self.activation_lstm,\n",
    "                       dropout_U=self.drop_out))\n",
    "        for i in range(self.dense_layer-1):\n",
    "            model.add(Dense(output_dim=self.output_dim,\n",
    "                        activation=self.activation_last))\n",
    "        model.add(Dense(output_dim=output_dim,\n",
    "                        input_dim=self.output_dim,\n",
    "                        activation=self.activation_last))\n",
    "        # configure the learning process\n",
    "        model.compile(loss=self.loss, optimizer=self.optimizer, metrics=['accuracy'])\n",
    "        # train the model with fixed number of epoches\n",
    "        model.fit(x=trainX, y=trainY, nb_epoch=self.nb_epoch, batch_size=self.batch_size, validation_data=(testX, testY))\n",
    "        # store model to json file\n",
    "        model_json = model.to_json()\n",
    "        with open(model_path, \"w\") as json_file:\n",
    "            json_file.write(model_json)\n",
    "        # store model weights to hdf5 file\n",
    "        if model_weight_path:\n",
    "            if os.path.exists(model_weight_path):\n",
    "                os.remove(model_weight_path)\n",
    "            model.save_weights(model_weight_path) # eg: model_weight.h5\n",
    "        return model"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
