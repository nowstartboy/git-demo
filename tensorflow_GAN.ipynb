{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Energy Based Generative Adversarial Networks (EBGAN): https://arxiv.org/pdf/1609.03126v2.pdf\n",
    "<blog.topspeedsnail.com>\n",
    "由于我把Python升级到了3.6破坏了开发环境, 暂时先使用Python 2.7 \n",
    "\"\"\"\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import scipy.misc as misc\n",
    " \n",
    "CELEBA_DATE_DIR= 'E:/machine_data/img_align_celeba'\n",
    " \n",
    "train_images = []\n",
    "for image_filename in os.listdir(CELEBA_DATE_DIR):\n",
    "\tif image_filename.endswith('.jpg'):\n",
    "\t\ttrain_images.append(os.path.join(CELEBA_DATE_DIR, image_filename))\n",
    " \n",
    "random.shuffle(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "202599"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'E:/machine_data/img_align_celeba\\\\146461.jpg'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "没找到模型\n",
      "0 25.1665 3.26108\n",
      "1 26.6273 1.40371\n",
      "2 26.9079 1.2318\n",
      "3 26.6496 1.60276\n",
      "4 25.7669 1.81184\n",
      "5 25.5186 1.60144\n",
      "6 25.2254 2.5547\n",
      "7 24.3438 3.85737\n",
      "8 23.6126 4.27899\n",
      "9 24.5086 3.39041\n",
      "10 22.3149 4.18945\n",
      "11 21.5637 5.24133\n",
      "12 20.8866 5.75542\n",
      "13 20.4531 4.26361\n",
      "14 21.951 3.42841\n",
      "15 21.9894 3.6197\n",
      "16 21.8096 4.40984\n",
      "17 20.9437 6.17221\n",
      "18 22.1828 6.20608\n",
      "19 19.5004 8.44077\n",
      "20 18.677 8.0283\n",
      "21 18.357 6.90434\n",
      "22 19.6669 7.73824\n",
      "23 18.5826 6.62473\n",
      "24 20.8411 5.12408\n",
      "25 20.7248 5.28592\n",
      "26 20.6885 5.54607\n",
      "27 20.474 5.90951\n",
      "28 20.3122 5.90231\n",
      "29 20.1852 6.11275\n",
      "30 19.7635 7.61392\n",
      "31 19.0461 9.42096\n",
      "32 19.1038 5.5674\n",
      "33 20.053 5.4331\n",
      "34 20.3325 5.83827\n",
      "35 20.3733 5.6743\n",
      "36 20.5494 5.35022\n",
      "37 20.4075 5.14428\n",
      "38 21.0353 5.56617\n",
      "39 21.0899 6.22162\n",
      "40 20.5679 5.32428\n",
      "41 20.7491 7.88489\n",
      "42 21.38 5.76768\n",
      "43 21.5702 5.74784\n",
      "44 21.0909 6.60901\n",
      "45 20.4503 6.69934\n",
      "46 21.1383 5.81025\n",
      "47 22.2935 4.69825\n",
      "48 22.6131 4.07494\n",
      "49 22.966 3.62788\n",
      "50 22.905 4.13473\n",
      "51 22.4797 6.8866\n",
      "52 20.5978 5.72043\n",
      "53 21.356 9.08483\n",
      "54 21.6839 7.29877\n",
      "55 21.0804 6.04354\n",
      "56 21.5076 5.464\n",
      "57 21.6814 6.03137\n",
      "58 20.9923 6.15293\n",
      "59 22.0608 4.5923\n",
      "60 22.8804 5.71695\n",
      "61 22.7355 7.60436\n",
      "62 21.9208 9.62696\n",
      "63 20.9519 8.39297\n",
      "64 21.3278 6.95784\n",
      "65 20.8964 4.78462\n",
      "66 22.1884 4.0022\n",
      "67 22.6528 3.82295\n",
      "68 22.9346 3.93652\n",
      "69 22.6962 4.95173\n",
      "70 22.3231 8.27804\n",
      "71 20.3583 11.2601\n",
      "72 21.9062 9.84742\n",
      "73 22.4758 8.54955\n",
      "74 20.0078 7.92879\n",
      "75 19.0107 5.75686\n",
      "76 21.3281 3.54339\n",
      "77 22.9244 2.89647\n",
      "78 22.9364 2.9144\n",
      "79 23.1269 3.64381\n",
      "80 22.7701 4.99295\n",
      "81 21.889 5.78516\n",
      "82 22.0508 7.43542\n",
      "83 21.6314 8.51275\n",
      "84 22.0662 7.72421\n",
      "85 22.436 5.61182\n",
      "86 21.9087 5.03944\n",
      "87 21.537 5.07178\n",
      "88 21.566 6.09479\n",
      "89 21.0855 5.81419\n",
      "90 22.1559 5.1004\n",
      "91 21.6616 4.55386\n",
      "92 21.7748 4.79138\n",
      "93 21.5834 4.86475\n",
      "94 21.7351 5.04743\n",
      "95 21.5931 5.34073\n",
      "96 21.5623 6.66841\n",
      "97 20.879 7.54671\n",
      "98 21.0905 6.78584\n",
      "99 20.3606 6.30731\n",
      "100 19.5489 8.81757\n",
      "101 19.943 7.38446\n",
      "102 20.2018 7.38835\n",
      "103 20.4433 7.12272\n",
      "104 20.1242 7.28973\n",
      "105 20.6377 5.69479\n",
      "106 20.7643 6.24033\n",
      "107 20.3553 7.93392\n",
      "108 20.3108 7.54365\n",
      "109 20.5355 6.33164\n",
      "110 20.7799 5.07932\n",
      "111 21.737 4.22182\n",
      "112 22.462 4.26423\n",
      "113 21.771 5.04343\n",
      "114 21.3967 5.38882\n",
      "115 21.3471 6.36249\n",
      "116 21.1592 6.75323\n",
      "117 20.6545 7.99389\n",
      "118 20.4419 7.2511\n",
      "119 21.0271 6.22503\n",
      "120 21.6923 6.11443\n",
      "121 21.6402 7.03294\n",
      "122 21.2138 7.40803\n",
      "123 21.1287 7.47187\n",
      "124 20.8838 7.25297\n",
      "125 20.8332 6.67038\n",
      "126 20.6927 6.26595\n",
      "127 20.9536 6.72823\n",
      "128 20.8126 7.77842\n",
      "129 20.7756 8.03819\n",
      "130 21.1731 6.79573\n",
      "131 21.2138 6.22973\n",
      "132 21.0609 6.12182\n",
      "133 21.5053 7.49845\n",
      "134 20.7752 9.5371\n",
      "135 21.021 8.54442\n",
      "136 20.2253 6.87675\n",
      "137 20.4958 5.29512\n",
      "138 21.3334 5.19719\n",
      "139 21.0992 5.32981\n",
      "140 21.6657 4.83327\n",
      "141 22.2674 4.82555\n",
      "142 21.9172 6.94256\n",
      "143 20.2299 10.34\n",
      "144 18.6761 11.7385\n",
      "145 19.7519 10.6239\n",
      "146 20.6679 9.83979\n",
      "147 20.087 8.7091\n",
      "148 19.715 7.88749\n",
      "149 19.8854 7.171\n",
      "150 20.5322 6.00019\n",
      "151 21.7664 5.15969\n",
      "152 22.2354 5.13335\n",
      "153 22.0534 5.17443\n",
      "154 21.7823 5.30883\n",
      "155 21.6466 5.82632\n",
      "156 21.9077 5.39158\n",
      "157 22.5984 4.50522\n",
      "158 23.0761 4.20082\n",
      "159 23.2138 4.29075\n",
      "160 22.8463 5.26656\n",
      "161 22.0457 4.61518\n",
      "162 22.1703 5.56879\n",
      "163 21.3117 5.85264\n",
      "164 21.7478 4.42946\n",
      "165 22.3334 4.94973\n",
      "166 21.4576 6.24246\n",
      "167 20.9061 7.09716\n",
      "168 20.8646 8.12431\n",
      "169 20.637 7.22664\n",
      "170 20.5009 6.51793\n",
      "171 20.3976 5.46351\n",
      "172 21.3194 5.11032\n",
      "173 21.37 6.34357\n",
      "174 21.0686 6.58105\n",
      "175 21.1426 6.42648\n",
      "176 21.5051 5.49437\n",
      "177 21.5767 5.16499\n",
      "178 21.6031 5.46185\n",
      "179 21.3944 5.89107\n",
      "180 21.3329 6.39295\n",
      "181 21.3849 5.87919\n",
      "182 22.2885 5.40602\n",
      "183 22.6637 6.9789\n",
      "184 22.1661 6.704\n",
      "185 21.6493 6.37922\n",
      "186 21.1251 6.55585\n",
      "187 21.0427 6.75149\n",
      "188 20.699 6.35747\n",
      "189 20.7148 6.23238\n",
      "190 20.6267 6.11175\n",
      "191 20.5094 6.60493\n",
      "192 20.2127 6.6895\n",
      "193 20.3269 6.32746\n",
      "194 20.6527 6.00541\n",
      "195 21.2436 6.2648\n",
      "196 20.8813 10.0276\n",
      "197 20.2705 9.0049\n",
      "198 22.5616 6.28889\n",
      "199 22.0079 4.90133\n",
      "200 21.6012 4.15719\n",
      "201 21.9375 5.01236\n",
      "202 22.0094 6.33367\n",
      "203 21.0778 10.5565\n",
      "204 19.4224 11.5155\n",
      "205 20.041 10.4759\n",
      "206 20.6368 8.73024\n",
      "207 19.9299 7.40003\n",
      "208 19.779 7.12045\n",
      "209 19.61 6.80106\n",
      "210 19.924 6.10782\n",
      "211 20.6453 5.64837\n",
      "212 20.8116 6.00598\n",
      "213 20.9119 5.80973\n",
      "214 21.3178 5.38333\n",
      "215 21.6593 6.11445\n",
      "216 20.9775 8.47698\n",
      "217 19.3856 10.7341\n",
      "218 18.1118 11.2656\n",
      "219 18.3413 10.7034\n",
      "220 18.9649 10.1115\n",
      "221 19.1448 9.33784\n",
      "222 18.9133 7.95449\n",
      "223 20.0562 6.69942\n",
      "224 21.1734 6.69298\n",
      "225 21.4279 7.68249\n",
      "226 21.2874 7.89979\n",
      "227 21.734 7.08105\n",
      "228 21.6946 6.23481\n",
      "229 21.9512 6.09026\n",
      "230 21.9875 6.70258\n",
      "231 21.2821 7.28866\n",
      "232 21.0928 7.54744\n",
      "233 20.4627 8.75631\n",
      "234 19.8873 8.97472\n",
      "235 19.875 8.1761\n",
      "236 19.6091 7.57589\n",
      "237 19.9967 6.76799\n",
      "238 20.3789 6.36704\n",
      "239 21.0236 6.32464\n",
      "240 20.9381 7.30156\n",
      "241 20.6 8.28472\n",
      "242 20.3329 7.6859\n",
      "243 20.9204 6.41622\n",
      "244 21.579 5.60913\n"
     ]
    }
   ],
   "source": [
    "\n",
    "batch_size = 64\n",
    "num_batch = len(train_images) // batch_size\n",
    " \n",
    "# 图像大小和channel\n",
    "IMAGE_SIZE = 64\n",
    "IMAGE_CHANNEL = 3\n",
    " \n",
    "def get_next_batch(pointer):\n",
    "\timage_batch = []\n",
    "\timages = train_images[pointer*batch_size:(pointer+1)*batch_size]\n",
    "\tfor img in images:\n",
    "\t\timage = cv2.imread(img)\n",
    "\t\timage = cv2.resize(image, (IMAGE_SIZE, IMAGE_SIZE))\n",
    "\t\timage = image.astype('float32') / 127.5 - 1\n",
    "\t\timage_batch.append(image)\n",
    "\treturn image_batch\n",
    " \n",
    "# noise\n",
    "z_dim = 100\n",
    "noise = tf.placeholder(tf.float32, [None, z_dim], name='noise')\n",
    " \n",
    "X = tf.placeholder(tf.float32, [batch_size, IMAGE_SIZE, IMAGE_SIZE, IMAGE_CHANNEL], name='X')\n",
    "# 是否在训练阶段\n",
    "train_phase = tf.placeholder(tf.bool)\n",
    " \n",
    "# http://stackoverflow.com/a/34634291/2267819\n",
    "def batch_norm(x, beta, gamma, phase_train, scope='bn', decay=0.9, eps=1e-5):\n",
    "\twith tf.variable_scope(scope):\n",
    "\t\t#beta = tf.get_variable(name='beta', shape=[n_out], initializer=tf.constant_initializer(0.0), trainable=True)\n",
    "\t\t#gamma = tf.get_variable(name='gamma', shape=[n_out], initializer=tf.random_normal_initializer(1.0, stddev), trainable=True)\n",
    "\t\tbatch_mean, batch_var = tf.nn.moments(x, [0, 1, 2], name='moments')\n",
    "\t\tema = tf.train.ExponentialMovingAverage(decay=decay)  #滑动平均模型\n",
    " \n",
    "\t\tdef mean_var_with_update():\n",
    "\t\t\tema_apply_op = ema.apply([batch_mean, batch_var])\n",
    "\t\t\twith tf.control_dependencies([ema_apply_op]):  #tf.control_dependencies()设计是用来控制计算流图的，给图中的某些计算指定顺序\n",
    "\t\t\t\treturn tf.identity(batch_mean), tf.identity(batch_var)\n",
    "        # tf.cond 与 tf.control_dependencies 的控制问题\n",
    "\t\tmean, var = tf.cond(phase_train, mean_var_with_update, lambda: (ema.average(batch_mean), ema.average(batch_var)))\n",
    "\t\tnormed = tf.nn.batch_normalization(x, mean, var, beta, gamma, eps)\n",
    "\treturn normed\n",
    " \n",
    "# 重用变量出了点问题, 先用dict\n",
    "generator_variables_dict = {\n",
    "\t\"W_1\": tf.Variable(tf.truncated_normal([z_dim, 2 * IMAGE_SIZE * IMAGE_SIZE], stddev=0.02), name='Generator/W_1'),\n",
    "\t\"b_1\": tf.Variable(tf.constant(0.0, shape=[2 * IMAGE_SIZE * IMAGE_SIZE]), name='Generator/b_1'),\n",
    "\t'beta_1': tf.Variable(tf.constant(0.0, shape=[512]), name='Generator/beta_1'),\n",
    "\t'gamma_1': tf.Variable(tf.random_normal(shape=[512], mean=1.0, stddev=0.02), name='Generator/gamma_1'),\n",
    " \n",
    "\t\"W_2\": tf.Variable(tf.truncated_normal([5, 5, 256, 512], stddev=0.02), name='Generator/W_2'),\n",
    "\t\"b_2\": tf.Variable(tf.constant(0.0, shape=[256]), name='Generator/b_2'),\n",
    "\t'beta_2': tf.Variable(tf.constant(0.0, shape=[256]), name='Generator/beta_2'),\n",
    "\t'gamma_2': tf.Variable(tf.random_normal(shape=[256], mean=1.0, stddev=0.02), name='Generator/gamma_2'),\n",
    " \n",
    "\t\"W_3\": tf.Variable(tf.truncated_normal([5, 5, 128, 256], stddev=0.02), name='Generator/W_3'),\n",
    "\t\"b_3\": tf.Variable(tf.constant(0.0, shape=[128]), name='Generator/b_3'),\n",
    "\t'beta_3': tf.Variable(tf.constant(0.0, shape=[128]), name='Generator/beta_3'),\n",
    "\t'gamma_3': tf.Variable(tf.random_normal(shape=[128], mean=1.0, stddev=0.02), name='Generator/gamma_3'),\n",
    " \n",
    "\t\"W_4\": tf.Variable(tf.truncated_normal([5, 5, 64, 128], stddev=0.02), name='Generator/W_4'),\n",
    "\t\"b_4\": tf.Variable(tf.constant(0.0, shape=[64]), name='Generator/b_4'),\n",
    "\t'beta_4': tf.Variable(tf.constant(0.0, shape=[64]), name='Generator/beta_4'),\n",
    "\t'gamma_4': tf.Variable(tf.random_normal(shape=[64], mean=1.0, stddev=0.02), name='Generator/gamma_4'),\n",
    " \n",
    "\t\"W_5\": tf.Variable(tf.truncated_normal([5, 5, IMAGE_CHANNEL, 64], stddev=0.02), name='Generator/W_5'),\n",
    "\t\"b_5\": tf.Variable(tf.constant(0.0, shape=[IMAGE_CHANNEL]), name='Generator/b_5')\n",
    "}\n",
    "# Generator\n",
    "def generator(noise):\n",
    "\twith tf.variable_scope(\"Generator\"):\n",
    "\t\tout_1 = tf.matmul(noise, generator_variables_dict[\"W_1\"]) + generator_variables_dict['b_1']\n",
    "\t\tout_1 = tf.reshape(out_1, [-1, IMAGE_SIZE//16, IMAGE_SIZE//16, 512])\n",
    "\t\tout_1 = batch_norm(out_1, generator_variables_dict[\"beta_1\"], generator_variables_dict[\"gamma_1\"], train_phase, scope='bn_1')\n",
    "\t\tout_1 = tf.nn.relu(out_1, name='relu_1')\n",
    " \n",
    "\t\tout_2 = tf.nn.conv2d_transpose(out_1, generator_variables_dict['W_2'],  output_shape=tf.stack([tf.shape(out_1)[0], IMAGE_SIZE//8, IMAGE_SIZE//8, 256]), strides=[1, 2, 2, 1], padding='SAME')\n",
    "\t\tout_2 = tf.nn.bias_add(out_2, generator_variables_dict['b_2'])\n",
    "\t\tout_2 = batch_norm(out_2, generator_variables_dict[\"beta_2\"], generator_variables_dict[\"gamma_2\"], train_phase, scope='bn_2')\n",
    "\t\tout_2 = tf.nn.relu(out_2, name='relu_2')\n",
    " \n",
    "\t\tout_3 = tf.nn.conv2d_transpose(out_2, generator_variables_dict['W_3'],  output_shape=tf.stack([tf.shape(out_2)[0], IMAGE_SIZE//4, IMAGE_SIZE//4, 128]), strides=[1, 2, 2, 1], padding='SAME')\n",
    "\t\tout_3 = tf.nn.bias_add(out_3, generator_variables_dict['b_3'])\n",
    "\t\tout_3 = batch_norm(out_3, generator_variables_dict[\"beta_3\"], generator_variables_dict[\"gamma_3\"], train_phase, scope='bn_3')\n",
    "\t\tout_3 = tf.nn.relu(out_3, name='relu_3')\n",
    "\t\t\n",
    "\t\tout_4 = tf.nn.conv2d_transpose(out_3, generator_variables_dict['W_4'],  output_shape=tf.stack([tf.shape(out_3)[0], IMAGE_SIZE//2, IMAGE_SIZE//2, 64]), strides=[1, 2, 2, 1], padding='SAME')\n",
    "\t\tout_4 = tf.nn.bias_add(out_4, generator_variables_dict['b_4'])\n",
    "\t\tout_4 = batch_norm(out_4, generator_variables_dict[\"beta_4\"], generator_variables_dict[\"gamma_4\"], train_phase, scope='bn_4')\n",
    "\t\tout_4 = tf.nn.relu(out_4, name='relu_4')\n",
    " \n",
    "\t\tout_5 = tf.nn.conv2d_transpose(out_4, generator_variables_dict['W_5'],  output_shape=tf.stack([tf.shape(out_4)[0], IMAGE_SIZE, IMAGE_SIZE, IMAGE_CHANNEL]), strides=[1, 2, 2, 1], padding='SAME')\n",
    "\t\tout_5 = tf.nn.bias_add(out_5, generator_variables_dict['b_5'])\n",
    "\t\tout_5 = tf.nn.tanh(out_5, name='tanh_5')\n",
    " \n",
    "\t\treturn out_5\n",
    " \n",
    "discriminator_variables_dict = {\n",
    "\t\"W_1\": tf.Variable(tf.truncated_normal([4, 4, IMAGE_CHANNEL, 32], stddev=0.002), name='Discriminator/W_1'),\n",
    "\t\"b_1\": tf.Variable(tf.constant(0.0, shape=[32]), name='Discriminator/b_1'),\n",
    "\t'beta_1': tf.Variable(tf.constant(0.0, shape=[32]), name='Discriminator/beta_1'),\n",
    "\t'gamma_1': tf.Variable(tf.random_normal(shape=[32], mean=1.0, stddev=0.02), name='Discriminator/gamma_1'),\n",
    " \n",
    "\t\"W_2\": tf.Variable(tf.truncated_normal([4, 4, 32, 64], stddev=0.002), name='Discriminator/W_2'),\n",
    "\t\"b_2\": tf.Variable(tf.constant(0.0, shape=[64]), name='Discriminator/b_2'),\n",
    "\t'beta_2': tf.Variable(tf.constant(0.0, shape=[64]), name='Discriminator/beta_2'),\n",
    "\t'gamma_2': tf.Variable(tf.random_normal(shape=[64], mean=1.0, stddev=0.02), name='Discriminator/gamma_2'),\n",
    " \n",
    "\t\"W_3\": tf.Variable(tf.truncated_normal([4, 4, 64, 128], stddev=0.002), name='Discriminator/W_3'),\n",
    "\t\"b_3\": tf.Variable(tf.constant(0.0, shape=[128]), name='Discriminator/b_3'),\n",
    "\t'beta_3': tf.Variable(tf.constant(0.0, shape=[128]), name='Discriminator/beta_3'),\n",
    "\t'gamma_3': tf.Variable(tf.random_normal(shape=[128], mean=1.0, stddev=0.02), name='Discriminator/gamma_3'),\n",
    " \n",
    "\t\"W_4\": tf.Variable(tf.truncated_normal([4, 4, 64, 128], stddev=0.002), name='Discriminator/W_4'),\n",
    "\t\"b_4\": tf.Variable(tf.constant(0.0, shape=[64]), name='Discriminator/b_4'),\n",
    "\t'beta_4': tf.Variable(tf.constant(0.0, shape=[64]), name='Discriminator/beta_4'),\n",
    "\t'gamma_4': tf.Variable(tf.random_normal(shape=[64], mean=1.0, stddev=0.02), name='Discriminator/gamma_4'),\n",
    " \n",
    "\t\"W_5\": tf.Variable(tf.truncated_normal([4, 4, 32, 64], stddev=0.002), name='Discriminator/W_5'),\n",
    "\t\"b_5\": tf.Variable(tf.constant(0.0, shape=[32]), name='Discriminator/b_5'),\n",
    "\t'beta_5': tf.Variable(tf.constant(0.0, shape=[32]), name='Discriminator/beta_5'),\n",
    "\t'gamma_5': tf.Variable(tf.random_normal(shape=[32], mean=1.0, stddev=0.02), name='Discriminator/gamma_5'),\n",
    " \n",
    "\t\"W_6\": tf.Variable(tf.truncated_normal([4, 4, 3, 32], stddev=0.002), name='Discriminator/W_6'),\n",
    "\t\"b_6\": tf.Variable(tf.constant(0.0, shape=[3]), name='Discriminator/b_6')\n",
    "}\n",
    "# Discriminator\n",
    "def discriminator(input_images):\n",
    "\twith tf.variable_scope(\"Discriminator\"):\n",
    "\t\t# Encoder\n",
    "\t\tout_1 = tf.nn.conv2d(input_images, discriminator_variables_dict['W_1'], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\t\tout_1 = tf.nn.bias_add(out_1, discriminator_variables_dict['b_1'])\n",
    "\t\tout_1 = batch_norm(out_1, discriminator_variables_dict['beta_1'], discriminator_variables_dict['gamma_1'], train_phase, scope='bn_1')\n",
    "\t\tout_1 = tf.maximum(0.2 * out_1, out_1, 'leaky_relu_1')\n",
    " \n",
    "\t\tout_2 = tf.nn.conv2d(out_1, discriminator_variables_dict['W_2'], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\t\tout_2 = tf.nn.bias_add(out_2, discriminator_variables_dict['b_2'])\n",
    "\t\tout_2 = batch_norm(out_2, discriminator_variables_dict['beta_2'], discriminator_variables_dict['gamma_2'], train_phase, scope='bn_2')\n",
    "\t\tout_2 = tf.maximum(0.2 * out_2, out_2, 'leaky_relu_2')\n",
    " \n",
    "\t\tout_3 = tf.nn.conv2d(out_2, discriminator_variables_dict['W_3'], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\t\tout_3 = tf.nn.bias_add(out_3, discriminator_variables_dict['b_3'])\n",
    "\t\tout_3 = batch_norm(out_3, discriminator_variables_dict['beta_3'], discriminator_variables_dict['gamma_3'], train_phase, scope='bn_3')\n",
    "\t\tout_3 = tf.maximum(0.2 * out_3, out_3, 'leaky_relu_3')\n",
    "\t\tencode = tf.reshape(out_3, [-1, 2*IMAGE_SIZE*IMAGE_SIZE])\n",
    " \n",
    "\t\t# Decoder\n",
    "\t\tout_3 = tf.reshape(encode, [-1, IMAGE_SIZE//8, IMAGE_SIZE//8, 128])\n",
    "\t\t\n",
    "\t\tout_4 = tf.nn.conv2d_transpose(out_3, discriminator_variables_dict['W_4'],  output_shape=tf.stack([tf.shape(out_3)[0], IMAGE_SIZE//4, IMAGE_SIZE//4, 64]), strides=[1, 2, 2, 1], padding='SAME')\n",
    "\t\tout_4 = tf.nn.bias_add(out_4, discriminator_variables_dict['b_4'])\n",
    "\t\tout_4 = batch_norm(out_4, discriminator_variables_dict['beta_4'], discriminator_variables_dict['gamma_4'], train_phase, scope='bn_4')\n",
    "\t\tout_4 = tf.maximum(0.2 * out_4, out_4, 'leaky_relu_4')\n",
    " \n",
    "\t\tout_5 = tf.nn.conv2d_transpose(out_4, discriminator_variables_dict['W_5'],  output_shape=tf.stack([tf.shape(out_4)[0], IMAGE_SIZE//2, IMAGE_SIZE//2, 32]), strides=[1, 2, 2, 1], padding='SAME')\n",
    "\t\tout_5 = tf.nn.bias_add(out_5, discriminator_variables_dict['b_5'])\n",
    "\t\tout_5 = batch_norm(out_5, discriminator_variables_dict['beta_5'], discriminator_variables_dict['gamma_5'], train_phase, scope='bn_5')\n",
    "\t\tout_5 = tf.maximum(0.2 * out_5, out_5, 'leaky_relu_5')\n",
    " \n",
    "\t\tout_6 = tf.nn.conv2d_transpose(out_5, discriminator_variables_dict['W_6'],  output_shape=tf.stack([tf.shape(out_5)[0], IMAGE_SIZE, IMAGE_SIZE, 3]), strides=[1, 2, 2, 1], padding='SAME')\n",
    "\t\tout_6 = tf.nn.bias_add(out_6, discriminator_variables_dict['b_6'])\n",
    "\t\tdecoded = tf.nn.tanh(out_6, name=\"tanh_6\")\n",
    " \n",
    "\t\treturn encode, decoded\n",
    " \n",
    "# mean squared errors\n",
    "_, real_decoded = discriminator(X)\n",
    "real_loss = tf.sqrt(2 * tf.nn.l2_loss(real_decoded - X)) / batch_size\n",
    " \n",
    "fake_image = generator(noise)\n",
    "_, fake_decoded = discriminator(fake_image)\n",
    "fake_loss = tf.sqrt(2 * tf.nn.l2_loss(fake_decoded - fake_image)) / batch_size\n",
    " \n",
    "# loss\n",
    "# D_loss = real_loss + tf.maximum(1 - fake_loss, 0)\n",
    "margin = 20\n",
    "D_loss = margin - fake_loss + real_loss\n",
    "G_loss = fake_loss # no pt\n",
    " \n",
    "def optimizer(loss, d_or_g):\n",
    "\toptim = tf.train.AdamOptimizer(learning_rate=0.001, beta1=0.5)\n",
    "\t#print([v.name for v in tf.trainable_variables() if v.name.startswith(d_or_g)])\n",
    "\tvar_list = [v for v in tf.trainable_variables() if v.name.startswith(d_or_g)]\n",
    "\tgradient = optim.compute_gradients(loss, var_list=var_list)\n",
    "\treturn optim.apply_gradients(gradient)\n",
    " \n",
    "train_op_G = optimizer(G_loss, 'Generator')\n",
    "train_op_D = optimizer(D_loss, 'Discriminator')\n",
    " \n",
    "with tf.Session() as sess:\n",
    "\tsess.run(tf.global_variables_initializer(), feed_dict={train_phase: True})\n",
    "\tsaver = tf.train.Saver()\n",
    " \n",
    "\t# 恢复前一次训练\n",
    "\tckpt = tf.train.get_checkpoint_state('.')\n",
    "\tif ckpt != None:\n",
    "\t\tprint(ckpt.model_checkpoint_path)\n",
    "\t\tsaver.restore(sess, ckpt.model_checkpoint_path)\n",
    "\telse:\n",
    "\t\tprint(\"没找到模型\")\n",
    " \n",
    "\tstep = 0\n",
    "\tfor i in range(40):\n",
    "\t\tfor j in range(num_batch):\n",
    "\t\t\tbatch_noise = np.random.uniform(-1.0, 1.0, size=[batch_size, z_dim]).astype(np.float32)\n",
    " \n",
    "\t\t\td_loss, _ = sess.run([D_loss, train_op_D], feed_dict={noise: batch_noise, X: get_next_batch(j), train_phase: True})\n",
    "\t\t\tg_loss, _ = sess.run([G_loss, train_op_G], feed_dict={noise: batch_noise, X: get_next_batch(j), train_phase: True})\n",
    "\t\t\tg_loss, _ = sess.run([G_loss, train_op_G], feed_dict={noise: batch_noise, X: get_next_batch(j), train_phase: True})\n",
    " \n",
    "\t\t\tprint(step, d_loss, g_loss)\n",
    " \n",
    "\t\t\t# 保存模型并生成图像\n",
    "\t\t\tif step % 100 == 0:\n",
    "\t\t\t\tsaver.save(sess, \"D:/python_code/model/GAN/celeba.model\", global_step=step)\n",
    " \n",
    "\t\t\t\ttest_noise = np.random.uniform(-1.0, 1.0, size=(5, z_dim)).astype(np.float32)\n",
    "\t\t\t\timages = sess.run(fake_image, feed_dict={noise: test_noise, train_phase: False})\n",
    " \n",
    "\t\t\t\tfor k in range(5):\n",
    "\t\t\t\t\timage = images[k, :, :, :]\n",
    "\t\t\t\t\timage += 1\n",
    "\t\t\t\t\timage *= 127.5\n",
    "\t\t\t\t\timage = np.clip(image, 0, 255).astype(np.uint8)\n",
    "\t\t\t\t\timage = np.reshape(image, (IMAGE_SIZE, IMAGE_SIZE, -1))\n",
    "\t\t\t\t\tmisc.imsave('D:/python_code/GAN_image/fake_image' + str(step) + str(k) + '.jpg', image)\n",
    " \n",
    "\t\t\tstep += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with g.control_dependencies([a, b]):\n",
    "   此处构建的操作在 `a` 和 `b`都被执行后才执行.\n",
    "  with g.control_dependencies([c, d]):\n",
    "    # 此处构建的操作在`a`, `b`, `c`, 和 `d`都被执行后才执行"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
